{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bxnkoxf270y"
   },
   "source": [
    "## **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PIXpOjx3DGc"
   },
   "source": [
    "### Business Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-chI7K4vyr3n"
   },
   "source": [
    "In today's dynamic business landscape, organizations are increasingly recognizing the pivotal role customer feedback plays in shaping the trajectory of their products and services. The ability to swiftly and effectively respond to customer input not only fosters enhanced customer experiences but also serves as a catalyst for growth, prolonged customer engagement, and the nurturing of lifetime value relationships. As a dedicated Product Manager or Product Analyst, staying attuned to the voice of your customers is not just a best practice; it's a strategic imperative.\n",
    "\n",
    "While your organization may be inundated with a wealth of customer-generated feedback and support tickets, your role entails much more than just processing these inputs. To make your efforts in managing customer experience and expectations truly impactful, you need a structured approach â€“ a method that allows you to discern the most pressing issues, set priorities, and allocate resources judiciously. One of the most effective strategies at your disposal is to harness the power of Support Ticket Categorization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZyyo5p53BTG"
   },
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trDwCVXRy-rn"
   },
   "source": [
    "Develop an advanced support ticket categorization system that accurately classifies incoming tickets, assigns relevant tags based on their content, implements mechanisms and generate the first response based on the sentiment for prioritizing tickets for prompt resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bonUQGu23RK"
   },
   "source": [
    "## **Installing and Importing Necessary Libraries and Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0rHx0ZC5Jbv"
   },
   "outputs": [],
   "source": [
    "# Installation for GPU llama-cpp-python\n",
    "# uncomment and run the following code in case GPU is being used\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.45 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QV8ksUtb8bk"
   },
   "outputs": [],
   "source": [
    "# Installation for CPU llama-cpp-python\n",
    "# uncomment and run the following code in case GPU is not being used\n",
    "\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=off\" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.45 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqY7XXCnl-Ak"
   },
   "source": [
    "**Note** : There may be an error related to a dependency issue thrown by the pip package. This can be ignored as it will not impact the execution of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awsKQRs-OYo8"
   },
   "outputs": [],
   "source": [
    "# For downloading the models from HF Hub\n",
    "!pip install huggingface_hub==0.20.3 pandas==1.5.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0x29JGHMqD74"
   },
   "outputs": [],
   "source": [
    "# Function to download the model from the Hugging Face model hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Importing the Llama class from the llama_cpp module\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Importing the json module\n",
    "import json\n",
    "\n",
    "# for loading and manipulating data\n",
    "import pandas as pd\n",
    "\n",
    "# for time computations\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTpWESc53dL9"
   },
   "source": [
    "## **Loading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zdj93fJqy305"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksv9hSCR4BM_"
   },
   "outputs": [],
   "source": [
    "# Complete the code to read the CSV file.\n",
    "data = pd.read_csv(\"support_ticket_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8qUEOcQ3j5q"
   },
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3YXcM8G3ljS"
   },
   "source": [
    "### Checking the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNOTBqaNVG4j"
   },
   "outputs": [],
   "source": [
    "# Complete the code to check the first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UO3pFis3rDj"
   },
   "source": [
    "### Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fLXRyDA4m3S"
   },
   "outputs": [],
   "source": [
    "# Complete the code to check the shape of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i1EB_O-3tJp"
   },
   "source": [
    "### Checking the missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rtx1knap5wRt"
   },
   "outputs": [],
   "source": [
    "# Complete the code to check for missing values in the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qP5KTLo3OOC"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWvf3R3An5K4"
   },
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF2F_YO_qGtV"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uk2q7vrc_TrO"
   },
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\", \n",
    "    filename=\"mistral-7b-instruct-v0.2.Q6_K.gguf\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI_T-0DWXRtD"
   },
   "outputs": [],
   "source": [
    "llm = Llama(\n",
    "     model_path=model_path,\n",
    "     n_ctx=1024, # Context window\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BbGah-FxY-i"
   },
   "outputs": [],
   "source": [
    "#uncomment and run the following code in case GPU is not being used\n",
    "\n",
    "# llm = Llama(\n",
    "#     model_path=model_path,\n",
    "#     n_ctx=1024, # Context window\n",
    "#     n_cores=-2 # Number of CPU cores to use\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8FxB-MBen3w"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PibZOe6aegGe"
   },
   "outputs": [],
   "source": [
    "# defining a function to parse the JSON output from the model\n",
    "def extract_json_data(json_str):\n",
    "    try:\n",
    "        # Find the indices of the opening and closing curly braces\n",
    "        json_start = json_str.find('{')\n",
    "        json_end = json_str.rfind('}')\n",
    "\n",
    "        if json_start != -1 and json_end != -1:\n",
    "            extracted_category = json_str[json_start:json_end + 1]  # Extract the JSON object\n",
    "            data_dict = json.loads(extracted_category)\n",
    "            return data_dict\n",
    "        else:\n",
    "            print(f\"Warning: JSON object not found in response: {json_str}\")\n",
    "            return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le80Djip27mc"
   },
   "source": [
    "## **Task 1: Ticket Categorization and Returning Structured Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2opKxTRX3Ksw"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzdh6COH_615"
   },
   "outputs": [],
   "source": [
    "# Defining the response function for Task 1\n",
    "def response_1(prompt, ticket):\n",
    "    model_output = llm(\n",
    "        f\"\"\"\n",
    "        Q: {prompt}\n",
    "        Support ticket: {ticket}\n",
    "        A:\n",
    "        \"\"\",\n",
    "        max_tokens=50,     # Limit output to a short JSON\n",
    "        stop=[\"Q:\", \"\\n\"],\n",
    "        temperature=0.3,   # Lower temp for consistent classification\n",
    "        echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]  # Extract JSON portion\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4fvrtrB3P_G"
   },
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"You are an AI assistant. Categorize the support ticket into one of these categories: 'Login Issue', 'Payment Problem', 'Technical Bug', 'Account Management'. Return the result as JSON: {\"Category\": \"...\"}.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afxdh6opkyfj"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UinALS1l3XjW"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_1['model_response'] = data_1['support_ticket_text'].apply(lambda x: response_1(prompt_1, x))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bo0YlHPXAJfP"
   },
   "outputs": [],
   "source": [
    "print(\"Time taken \",(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHn-R-fx31Uq"
   },
   "outputs": [],
   "source": [
    "# Write the code to check the first five rows of the data to confirm whether the new column has been added\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbHTOL494CkV"
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(data_1.loc[i, 'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB9h31T54H4F"
   },
   "outputs": [],
   "source": [
    "print(data_1.loc[i, 'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLjf4Kgu41oJ"
   },
   "outputs": [],
   "source": [
    "# applying the function to the model response\n",
    "data_1['model_response_parsed'] = data_1['model_response'].apply(extract_json_data)\n",
    "data_1['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXi7nOzyeGdK"
   },
   "outputs": [],
   "source": [
    "data_1['model_response_parsed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnivjGUcUONC"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_1 = pd.json_normalize(data_1['model_response_parsed'])\n",
    "model_response_parsed_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V67nKkfUUd1c"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_1 = pd.concat([data_1, model_response_parsed_df_1], axis=1)\n",
    "data_with_parsed_model_output_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHxzez70U0Dv"
   },
   "outputs": [],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_1 = data_with_parsed_model_output_1.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z795llV0elBQ"
   },
   "source": [
    "## **Task 2: Creating Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWlFOeCFf5Zx"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSflU6-CBk29"
   },
   "outputs": [],
   "source": [
    "def response_2(prompt, ticket, category):\n",
    "    model_output = llm(\n",
    "        f\"\"\"\n",
    "        Q: {prompt}\n",
    "        Support ticket: {ticket}\n",
    "        Category: {category}\n",
    "        A:\n",
    "        \"\"\",\n",
    "        max_tokens=60,     # Enough for 2â€“3 tags\n",
    "        stop=[\"Q:\", \"\\n\"],\n",
    "        temperature=0.7,   # Slightly creative for generating varied tags\n",
    "        echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kODQ_X5Vf7gJ"
   },
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"Generate up to 3 relevant tags for the following support ticket based on its content and the category. Return JSON: {\"Tags\": [\"...\", \"...\"]}.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlnUmTSKlD-O"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEQu4_lUgcdW"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_2[\"model_response\"]=final_data_1[['support_ticket_text','Category']].apply(lambda x: response_2(prompt_2, x[0],x[1]),axis =1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GeduRusM1i3"
   },
   "outputs": [],
   "source": [
    "print(\"Time taken \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y023-XNxgpYd"
   },
   "outputs": [],
   "source": [
    "# Write the code to check the first five rows of the data to confirm whether the new column has been added\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqOM7mntgsJ6"
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(data_2.loc[i, 'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IayJkEP1gr96"
   },
   "outputs": [],
   "source": [
    "print(data_2.loc[i, 'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8CTPgPQhKcx"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_2['model_response_parsed'] = data_2['model_response'].apply(extract_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3om_9wk4W8_l"
   },
   "outputs": [],
   "source": [
    "data_2[\"model_response_parsed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PAke663hN3T"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_2 = pd.json_normalize(data_2['model_response_parsed'])\n",
    "model_response_parsed_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXJqZgh-hP4G"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_2 = pd.concat([data_2, model_response_parsed_df_2], axis=1)\n",
    "data_with_parsed_model_output_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsT9xR1FhSRZ"
   },
   "outputs": [],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_2 = data_with_parsed_model_output_2.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UAvaviZhUW4"
   },
   "outputs": [],
   "source": [
    "# Checking the value counts of Category column\n",
    "final_data_2['Tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NybVxPKS8k3"
   },
   "outputs": [],
   "source": [
    "final_data_2 = pd.concat([final_data_2,final_data_1[\"Category\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kt24BSz6THBr"
   },
   "outputs": [],
   "source": [
    "final_data_2 = final_data_2[[\"support_tick_id\",\"support_ticket_text\",\"Category\",\"Tags\"]]\n",
    "final_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdwE7rguh8sD"
   },
   "source": [
    "## **Task 3: Assigning Priority and ETA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FS158JYiUXY"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_3 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHjSvP9maGFt"
   },
   "outputs": [],
   "source": [
    "def response_3(prompt, ticket, category, tags):\n",
    "    model_output = llm(\n",
    "        f\"\"\"\n",
    "        Q: {prompt}\n",
    "        Support ticket: {ticket}\n",
    "        Category: {category}\n",
    "        Tags: {tags}\n",
    "        A:\n",
    "        \"\"\",\n",
    "        max_tokens=40,     # Short output: Priority + ETA\n",
    "        stop=[\"Q:\", \"\\n\"],\n",
    "        temperature=0.4,   # Slight randomness, but mostly deterministic\n",
    "        echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUHUh2mRiUUK"
   },
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"Based on the support ticket, category, and tags, assign a priority (Low, Medium, High) and an estimated resolution time in hours. Return JSON: {\"Priority\": \"...\", \"ETA\": \"...\"}.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VZ1BUwslKHD"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xC2Ygg4AiUR6"
   },
   "outputs": [],
   "source": [
    "# Applying generate_llama_response function on support_ticket_text column\n",
    "start = time.time()\n",
    "data_3['model_response'] = final_data_2[['support_ticket_text','Category','Tags']].apply(lambda x: response_3(prompt_3, x[0],x[1],x[2]),axis=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXnus6Akhmr8"
   },
   "outputs": [],
   "source": [
    "print(\"Time taken \",(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsvGelDZiUPL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write the code to check the first five rows of the data to confirm whether the new column has been added\n",
    "data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_iOXhT1iUMd"
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(data_3.loc[i, 'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlqV49CeiUJz"
   },
   "outputs": [],
   "source": [
    "print(data_3.loc[i, 'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1F87rEpm70v"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n",
    "data_3['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGLu4BJEnDQq"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n",
    "model_response_parsed_df_3.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4x7VEKDcnL11"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n",
    "data_with_parsed_model_output_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gz8WprxNnONN"
   },
   "outputs": [],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3Kmwtwvj_NO"
   },
   "outputs": [],
   "source": [
    "final_data_3 = pd.concat([final_data_3,final_data_2[[\"Category\",\"Tags\"]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVa9DmktkL-x"
   },
   "outputs": [],
   "source": [
    "final_data_3 = final_data_3[[\"support_tick_id\",\"support_ticket_text\",\"Category\",\"Tags\",\"Priority\",\"ETA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da_W2ybekZHD"
   },
   "outputs": [],
   "source": [
    "final_data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7m73qRcne4g"
   },
   "source": [
    "## **Task 4 - Creating a Draft Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDe0fY0tnpCS"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_4 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czJxKYmGlG98"
   },
   "outputs": [],
   "source": [
    "def response_4(prompt, ticket, category, tags, priority, eta):\n",
    "    model_output = llm(\n",
    "        f\"\"\"\n",
    "        Q: {prompt}\n",
    "        Support ticket: {ticket}\n",
    "        Category: {category}\n",
    "        Tags: {tags}\n",
    "        Priority: {priority}\n",
    "        ETA: {eta}\n",
    "        A:\n",
    "        \"\"\",\n",
    "        max_tokens=300,    # Allowing space for a well-formed reply\n",
    "        stop=[\"Q:\", \"\\n\"],\n",
    "        temperature=0.6,   # Balanced tone and variation\n",
    "        echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    return temp_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CYnMUZUnqkf"
   },
   "outputs": [],
   "source": [
    "prompt_4 = \"\"\"Write a professional support response email addressing the issue described in the ticket. Reference the category, tags, priority, and ETA in your message.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2iYQuTPmcyA"
   },
   "source": [
    "**Note** : For this task, we will not be using the *`extract_json_data`* function. Hence, the output from the model should be a plain string and not a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3UBRIwcnqg8"
   },
   "outputs": [],
   "source": [
    "#Applying generate_llama_response function on support_ticket_text column\n",
    "start = time.time()\n",
    "data_4['model_response'] = final_data_3[['support_ticket_text','Category','Tags','Priority','ETA']].apply(lambda x: response_4(prompt_4, x[0],x[1],x[2],x[3],x[4]),axis=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDtIp9Hmlf9l"
   },
   "outputs": [],
   "source": [
    "print(\"Time taken\",(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyIBbCkcnqeY"
   },
   "outputs": [],
   "source": [
    "# Write the code to check the first five rows of the data to confirm whether the new column has been added\n",
    "data_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWkqPHtinqcD"
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(data_4.loc[i, 'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uPa8jt8nqZq"
   },
   "outputs": [],
   "source": [
    "print(data_4.loc[i, 'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKlPGXvqpcZ0"
   },
   "outputs": [],
   "source": [
    "final_data_4 = pd.concat([final_data_3,data_4[\"model_response\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-azDlrGegrxL"
   },
   "outputs": [],
   "source": [
    "final_data_4.rename(columns={\"model_response\":\"Response\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHgTohqhhLMp"
   },
   "outputs": [],
   "source": [
    "final_data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQznlJqM2gSk"
   },
   "source": [
    "## **Model Output Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb0BE-W20_0K"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe of task-4\n",
    "final_data = final_data_4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txX3gIQ9WZtD"
   },
   "outputs": [],
   "source": [
    "final_data['Category'].value_counts()    # complete the code with the column name for the column containing ticket categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lf-BVS4I2nxJ"
   },
   "outputs": [],
   "source": [
    "final_data[\"Priority\"].value_counts() # complete the code with the column name for the column containing the priorities of the ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIkoCfUJ2ntq"
   },
   "outputs": [],
   "source": [
    "final_data[\"Priority\"].value_counts()# complete the code with the column name for the column containing ticket resolution ETA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6sgaBLR6t-j"
   },
   "source": [
    "Let's dive in a bit deeper here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxtC6q6V6ZSR"
   },
   "outputs": [],
   "source": [
    "final_data.groupby(['Category', 'ETA']).support_tick_id.count() # complete the code to group by based on the categories and ETA."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5Bxnkoxf270y",
    "3PIXpOjx3DGc",
    "VZyyo5p53BTG",
    "DXtapml31CHh",
    "2bonUQGu23RK",
    "uTpWESc53dL9",
    "j8qUEOcQ3j5q",
    "V3YXcM8G3ljS",
    "4UO3pFis3rDj",
    "8i1EB_O-3tJp",
    "0qP5KTLo3OOC",
    "oWvf3R3An5K4",
    "V8FxB-MBen3w",
    "le80Djip27mc",
    "z795llV0elBQ",
    "bdwE7rguh8sD",
    "f7m73qRcne4g",
    "EQznlJqM2gSk",
    "NpevKeiDiVuJ"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
